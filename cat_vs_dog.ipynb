{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "from glob                        import glob\n",
    "from scipy                       import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from matplotlib                  import pyplot as plt\n",
    "\n",
    "np.set_printoptions(precision = 4, linewidth = 100)\n",
    "\n",
    "from keras.utils.data_utils     import get_file\n",
    "from keras                      import backend as K\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils.data_utils     import get_file\n",
    "from keras.models               import Sequential\n",
    "from keras.layers.core          import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.pooling       import GlobalAveragePooling2D\n",
    "\n",
    "from keras.optimizers           import SGD, RMSprop, Adam\n",
    "from keras.preprocessing        import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the path to our data. The sample folder is used for prototyping purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'data/redux/'\n",
    "# path = 'data/redux/sample/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first define a function that we will use as a preprocessing to get our data in the same format that the VGG network takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32).reshape((3, 1, 1))\n",
    "def vgg_preprocess(x):\n",
    "    x = x - vgg_mean  # remove the mean value for each channel \n",
    "    return x[:, ::-1] # reverse the order of the colors to match the vgg network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a convolution block to the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_conv_block(model, layers, filters):\n",
    "    for _ in range(layers):\n",
    "        model.add(ZeroPadding2D((1, 1)))\n",
    "        model.add(Convolution2D(filters, 3, 3, activation = 'relu'))\n",
    "    model.add(MaxPooling2D((2, 2), strides = (2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a fully connected block to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_FC_block(model):\n",
    "    model.add(Dense(4096, activation = 'relu'))\n",
    "    model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now build our model according to the VGG network architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_vgg_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    # We first substart the mean value from each channel in order to center our data on 0. \n",
    "    # We also change the order of the channels to match the vgg definition.\n",
    "    model.add(Lambda(vgg_preprocess, input_shape = (3, 224, 224)))\n",
    "\n",
    "    # Then we add the convolution blocks to the model.\n",
    "    conv_parameters = [(2, 64), (2, 128), (3, 256), (3, 512), (3, 512)]\n",
    "    for layers, filters in conv_parameters:\n",
    "        add_conv_block(model, layers, filters)\n",
    "\n",
    "    # We then flatten the data since the we will not use the spacial\n",
    "    # information of the picture.\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # We now add the fully connected blocks.\n",
    "    add_FC_block(model)\n",
    "    add_FC_block(model)\n",
    "\n",
    "    # And to finish, we add the final softmax layer that output the predicted probability\n",
    "    # for each category.\n",
    "    model.add(Dense(1000, activation = 'softmax'))\n",
    "\n",
    "    # Now that our model is created, we load the weights that have already been trained. \n",
    "    filename = 'vgg16.h5'\n",
    "    f = get_file(filename, 'http://www.platform.ai/models/' + filename)\n",
    "    model.load_weights(f)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define the finetune function which takes vgg model and replace the last layer by a new layer which will, after a retraining, predict the probability of being a cat or a dog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compile_model(model, lr = 0.001):\n",
    "    model.compile(optimizer = Adam(lr = lr),\n",
    "                  loss      = 'categorical_crossentropy',\n",
    "                  metrics   = ['accuracy'])\n",
    "\n",
    "def finetune_model(model, batches):\n",
    "    model.pop()\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False # We do not want to change the weights of the core of the network.\n",
    "    model.add(Dense(batches.nb_class, activation = 'softmax'))\n",
    "    compile_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define the batch that we will use for the training of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(path, \n",
    "                gen        = image.ImageDataGenerator(), \n",
    "                shuffle    = True, \n",
    "                batch_size = 8, \n",
    "                class_mode = 'categorical'):\n",
    "    parameters = {\n",
    "        'directory'  : path,\n",
    "        'target_size': (224, 224),\n",
    "        'class_mode' : class_mode,\n",
    "        'shuffle'    : shuffle,\n",
    "        'batch_size' : batch_size\n",
    "    }\n",
    "    return gen.flow_from_directory(**parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = create_vgg_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batches     = get_batches(path + 'train', batch_size = batch_size)\n",
    "val_batches = get_batches(path + 'valid', batch_size = 2 * batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now finetune the model so that it fits our needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "finetune_model(model, batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "23000/23000 [==============================] - 570s - loss: 0.1218 - acc: 0.9682 - val_loss: 0.0821 - val_acc: 0.9770\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7ebffe8cd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_parameters = {\n",
    "    'generator'         : batches,\n",
    "    'samples_per_epoch' : batches.nb_sample,\n",
    "    'nb_epoch'          : 1,\n",
    "    'validation_data'   : val_batches,\n",
    "    'nb_val_samples'    : val_batches.nb_sample\n",
    "}\n",
    "model.fit_generator(**fit_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is finetuned, we can use it to make our predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_batches = get_batches(path + 'test', batch_size = batch_size * 2, shuffle = False, class_mode = None)\n",
    "predictions  = model.predict_generator(test_batches, test_batches.nb_sample)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the predictions, we save them in a file in order to submit it to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ids    = np.array([int(name[8 : -4]) for name in test_batches.filenames])\n",
    "is_dog = predictions[:, 1].clip(0.07, 0.93) # we clip the result to avoid being penalized by the log loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_dict = {\n",
    "    'id'    : ids,\n",
    "    'label' : is_dog\n",
    "}\n",
    "submission_df = pd.DataFrame(submission_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_filename = path + 'result/submission.csv'\n",
    "submission_df.to_csv(submission_filename, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='data/redux/result/submission.csv' target='_blank'>data/redux/result/submission.csv</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/courses/deeplearning1/nbs/data/redux/result/submission.csv"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(submission_filename)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
